{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMlkFJkKH0ngxiMF73ZsyI0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kirans1ngh/Machine-Learning-practice/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "iGJSQpqAVlTb"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# A class to represent our neural network\n",
        "class SimpleNeuralNetwork:\n",
        "    \"\"\"\n",
        "    A simple Neural Network with one hidden layer.\n",
        "\n",
        "    Attributes:\n",
        "        input_nodes (int): Number of neurons in the input layer.\n",
        "        hidden_nodes (int): Number of neurons in the hidden layer.\n",
        "        output_nodes (int): Number of neurons in the output layer.\n",
        "        learning_rate (float): The step size for updating weights and biases.\n",
        "        weights_ih (np.array): Weights matrix from Input to Hidden layer.\n",
        "        weights_ho (np.array): Weights matrix from Hidden to Output layer.\n",
        "        bias_h (np.array): Bias vector for the Hidden layer.\n",
        "        bias_o (np.array): Bias vector for the Output layer.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, input_nodes, hidden_nodes, output_nodes, learning_rate=0.1):\n",
        "        \"\"\"Initializes the network's architecture and parameters.\"\"\"\n",
        "\n",
        "        # --- 1. Define the architecture ---\n",
        "        self.input_nodes = input_nodes\n",
        "        self.hidden_nodes = hidden_nodes\n",
        "        self.output_nodes = output_nodes\n",
        "        self.learning_rate = learning_rate\n",
        "\n",
        "        # --- 2. Initialize weights and biases with random values ---\n",
        "        # Weights between Input and Hidden layers\n",
        "        # Shape: (number_of_hidden_nodes, number_of_input_nodes)\n",
        "        self.weights_ih = np.random.rand(self.hidden_nodes, self.input_nodes) - 0.5\n",
        "\n",
        "        # Weights between Hidden and Output layers\n",
        "        # Shape: (number_of_output_nodes, number_of_hidden_nodes)\n",
        "        self.weights_ho = np.random.rand(self.output_nodes, self.hidden_nodes) - 0.5\n",
        "\n",
        "        # Biases for the hidden layer\n",
        "        # Shape: (number_of_hidden_nodes, 1)\n",
        "        self.bias_h = np.random.rand(self.hidden_nodes, 1) - 0.5\n",
        "\n",
        "        # Biases for the output layer\n",
        "        # Shape: (number_of_output_nodes, 1)\n",
        "        self.bias_o = np.random.rand(self.output_nodes, 1) - 0.5\n",
        "\n",
        "    def _sigmoid(self, x):\n",
        "        \"\"\"The Sigmoid activation function.\"\"\"\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "\n",
        "    def _sigmoid_derivative(self, x):\n",
        "        \"\"\"The derivative of the Sigmoid function.\"\"\"\n",
        "        # Note: x is assumed to be the output of a sigmoid function already\n",
        "        return x * (1 - x)\n",
        "\n",
        "    def predict(self, inputs_list):\n",
        "        \"\"\"Performs forward propagation to make a prediction.\"\"\"\n",
        "\n",
        "        # Convert input list to a 2D numpy array (a column vector)\n",
        "        inputs = np.array(inputs_list, ndmin=2).T\n",
        "\n",
        "        # --- FORWARD PROPAGATION ---\n",
        "\n",
        "        # 1. Calculate signals into the hidden layer\n",
        "        hidden_inputs = np.dot(self.weights_ih, inputs) + self.bias_h\n",
        "        # 2. Calculate the signals emerging from the hidden layer\n",
        "        hidden_outputs = self._sigmoid(hidden_inputs)\n",
        "\n",
        "        # 3. Calculate signals into the final output layer\n",
        "        final_inputs = np.dot(self.weights_ho, hidden_outputs) + self.bias_o\n",
        "        # 4. Calculate the signals emerging from the final output layer\n",
        "        final_outputs = self._sigmoid(final_inputs)\n",
        "\n",
        "        return final_outputs\n",
        "\n",
        "    def train(self, inputs_list, targets_list):\n",
        "        \"\"\"Trains the network by performing one full cycle of fwd/bwd propagation.\"\"\"\n",
        "\n",
        "        # Convert input and target lists to 2D numpy arrays\n",
        "        inputs = np.array(inputs_list, ndmin=2).T\n",
        "        targets = np.array(targets_list, ndmin=2).T\n",
        "\n",
        "        # --- 1. FORWARD PROPAGATION (same as predict, but we need intermediate values) ---\n",
        "        hidden_inputs = np.dot(self.weights_ih, inputs) + self.bias_h\n",
        "        hidden_outputs = self._sigmoid(hidden_inputs)\n",
        "\n",
        "        final_inputs = np.dot(self.weights_ho, hidden_outputs) + self.bias_o\n",
        "        final_outputs = self._sigmoid(final_inputs)\n",
        "\n",
        "        # --- 2. BACKWARD PROPAGATION (The Learning Part) ---\n",
        "\n",
        "        # Calculate the error (target - actual)\n",
        "        output_errors = targets - final_outputs\n",
        "\n",
        "        # Calculate the gradient for the output layer\n",
        "        # Gradient = (Error * Derivative of Activation Function)\n",
        "        output_gradient = self._sigmoid_derivative(final_outputs) * output_errors\n",
        "\n",
        "        # Calculate the error for the hidden layer (propagated backward)\n",
        "        hidden_errors = np.dot(self.weights_ho.T, output_errors)\n",
        "\n",
        "        # Calculate the gradient for the hidden layer\n",
        "        hidden_gradient = self._sigmoid_derivative(hidden_outputs) * hidden_errors\n",
        "\n",
        "        # --- 3. UPDATE WEIGHTS AND BIASES ---\n",
        "\n",
        "        # Update weights for the links between the hidden and output layers\n",
        "        self.weights_ho += self.learning_rate * np.dot(output_gradient, hidden_outputs.T)\n",
        "\n",
        "        # Update weights for the links between the input and hidden layers\n",
        "        self.weights_ih += self.learning_rate * np.dot(hidden_gradient, inputs.T)\n",
        "\n",
        "        # Update the biases\n",
        "        self.bias_o += self.learning_rate * output_gradient\n",
        "        self.bias_h += self.learning_rate * hidden_gradient"
      ],
      "metadata": {
        "id": "bsZUzUGMVqZR"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an instance of the 3-2-1 network\n",
        "nn_321 = SimpleNeuralNetwork(input_nodes=3, hidden_nodes=2, output_nodes=1, learning_rate=0.2)\n",
        "\n",
        "# Create some dummy training data.\n",
        "# The inputs are \"normalized\" to be between 0 and 1.\n",
        "# Each row is a training example: [area, bedrooms, age]\n",
        "training_data_inputs = np.array([\n",
        "    [0.8, 0.1, 0.9],  # Input for target 0.1 (High area, low beds, old -> low price)\n",
        "    [0.2, 0.8, 0.7],  # Input for target 0.7 (Low area, high beds, old -> mid price)\n",
        "    [0.9, 0.8, 0.2]   # Input for target 0.9 (High area, high beds, new -> high price)\n",
        "])\n",
        "# Each row is the corresponding target output: [price_score]\n",
        "training_data_targets = np.array([\n",
        "    [0.1],\n",
        "    [0.7],\n",
        "    [0.9]\n",
        "])\n",
        "\n",
        "print(\"Initial Input-to-Hidden weights:\\n\", nn_321.weights_ih)\n",
        "print(\"\\nInitial Hidden-to-Output weights:\\n\", nn_321.weights_ho)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wsv6yIMYVtBO",
        "outputId": "a2b6ccc2-3dc4-406f-a3d9-e249a74a13f2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial Input-to-Hidden weights:\n",
            " [[ 0.21569994 -0.07292586 -0.27127706]\n",
            " [-0.24363736 -0.37229801 -0.40420386]]\n",
            "\n",
            "Initial Hidden-to-Output weights:\n",
            " [[ 0.47665621 -0.25752168]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the number of training cycles\n",
        "epochs = 5000\n",
        "\n",
        "print(\"Training the 3-2-1 network...\")\n",
        "for e in range(epochs):\n",
        "    # Loop through each record in our training data\n",
        "    for i in range(len(training_data_inputs)):\n",
        "        nn_321.train(training_data_inputs[i], training_data_targets[i])\n",
        "\n",
        "print(\"Training complete!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gU0qMv2iVwLj",
        "outputId": "87194963-5324-4116-b133-8dea246e1d8f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training the 3-2-1 network...\n",
            "Training complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the network with a new, unseen situation\n",
        "test_input = [0.85, 0.6, 0.3] # High area, mid beds, fairly new house\n",
        "prediction = nn_321.predict(test_input)\n",
        "\n",
        "print(f\"Test Input: {test_input}\")\n",
        "print(f\"Prediction (should be high, close to 0.9): {prediction[0][0]:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uc8ANlPqVyO9",
        "outputId": "1ed8b6cb-4cfa-46bc-bade-8a3490e0351e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Input: [0.85, 0.6, 0.3]\n",
            "Prediction (should be high, close to 0.9): 0.8241\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Create, Train, and Test a 4-3-2 Network ---\n",
        "\n",
        "# 1. Create the instance\n",
        "nn_432 = SimpleNeuralNetwork(input_nodes=4, hidden_nodes=3, output_nodes=2, learning_rate=0.2)\n",
        "\n",
        "# 2. Create the dummy data\n",
        "training_data_inputs_432 = np.array([\n",
        "    # area, beds, age, dist_city\n",
        "    [0.9, 0.8, 0.2, 0.1], # Should result in: High price, fast sell\n",
        "    [0.2, 0.3, 0.9, 0.8]  # Should result in: Low price, slow sell\n",
        "])\n",
        "# Targets: [price_score, sell_time_score] (high score = fast sell)\n",
        "training_data_targets_432 = np.array([\n",
        "    [0.9, 0.9],\n",
        "    [0.2, 0.1]\n",
        "])\n",
        "\n",
        "# 3. Train the network\n",
        "print(\"\\nTraining the 4-3-2 network...\")\n",
        "epochs = 5000\n",
        "for e in range(epochs):\n",
        "     for i in range(len(training_data_inputs_432)):\n",
        "        nn_432.train(training_data_inputs_432[i], training_data_targets_432[i])\n",
        "print(\"Training complete!\")\n",
        "\n",
        "\n",
        "# 4. Test the network\n",
        "test_input_432 = [0.7, 0.7, 0.4, 0.3] # Good house, pretty close to city\n",
        "prediction_432 = nn_432.predict(test_input_432)\n",
        "\n",
        "print(f\"\\nTest Input: {test_input_432}\")\n",
        "print(f\"Prediction (Price, Sell Time) (should be high for both):\")\n",
        "print(f\"  - Predicted Price Score: {prediction_432[0][0]:.4f}\")\n",
        "print(f\"  - Predicted Sell Time Score: {prediction_432[1][0]:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RpQVzmboV0p7",
        "outputId": "9f228201-2e43-4a1c-81ed-6daa7cd96f4f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training the 4-3-2 network...\n",
            "Training complete!\n",
            "\n",
            "Test Input: [0.7, 0.7, 0.4, 0.3]\n",
            "Prediction (Price, Sell Time) (should be high for both):\n",
            "  - Predicted Price Score: 0.8231\n",
            "  - Predicted Sell Time Score: 0.7983\n"
          ]
        }
      ]
    }
  ]
}
